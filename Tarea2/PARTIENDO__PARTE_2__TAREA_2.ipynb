{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PARTIENDO__PARTE_2__TAREA_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2frxeeuYp7uF",
        "outputId": "32a67737-419f-41d2-b9a8-fdc5540b7736"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import math\n",
        "import time\n",
        "import torch\n",
        "import torchtext\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch.nn as nn\n",
        "nltk.download('stopwords')\n",
        "import matplotlib.pyplot as plt\n",
        "from torchtext.vocab import GloVe\n",
        "from nltk.corpus import stopwords\n",
        "from torchtext import data, datasets\n",
        "from collections import defaultdict, Counter\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsUp4cWPp9dX",
        "outputId": "f84efe03-578a-477d-a3de-7da7d03c4b21"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9MfyGSpqN9Z"
      },
      "source": [
        "with open('drive/MyDrive/DeepLearningUC/Tarea2/Actividad2/SICK.txt') as file:\n",
        "  mensajes = file.readlines()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woNFfbHUy9UO",
        "outputId": "2c52dcac-00cb-49ad-f96b-5be7576a1f63"
      },
      "source": [
        "print(mensajes[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pair_ID\tsentence_A\tsentence_B\tentailment_label\trelatedness_score\tentailment_AB\tentailment_BA\tsentence_A_original\tsentence_B_original\tsentence_A_dataset\tsentence_B_dataset\tSemEval_set\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2fv_H7UrTP3"
      },
      "source": [
        "# 1: Sentence A\n",
        "# 2: Sentence B\n",
        "# 4: Relatedness_score\n",
        "# Last label: Set perteneciente\n",
        "\n",
        "all_data = []\n",
        "\n",
        "for i in range(len(mensajes)):\n",
        "  if i != 0:\n",
        "    all_data.append(mensajes[i].split('\\t'))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCGMd6qUwht7"
      },
      "source": [
        "mensajes_A_train = []\n",
        "mensajes_B_train = []\n",
        "scores_train = []\n",
        "\n",
        "mensajes_A_val = []\n",
        "mensajes_B_val = []\n",
        "scores_val = []\n",
        "\n",
        "mensajes_A_test = []\n",
        "mensajes_B_test = []\n",
        "scores_test = []"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIOtnt5pxN4G"
      },
      "source": [
        "for i in range(len(all_data)):\n",
        "\n",
        "  if all_data[i][11] == 'TRAIN\\n':\n",
        "    mensajes_A_train.append(all_data[i][1].lower())\n",
        "    mensajes_B_train.append(all_data[i][2].lower())\n",
        "    scores_train.append(float(all_data[i][4]))\n",
        "\n",
        "  elif all_data[i][11] == 'TRIAL\\n':\n",
        "    mensajes_A_val.append(all_data[i][1].lower())\n",
        "    mensajes_B_val.append(all_data[i][2].lower())\n",
        "    scores_val.append(float(all_data[i][4]))\n",
        "\n",
        "  elif all_data[i][11] == 'TEST\\n':\n",
        "    mensajes_A_test.append(all_data[i][1].lower())\n",
        "    mensajes_B_test.append(all_data[i][2].lower())\n",
        "    scores_test.append(float(all_data[i][4]))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wrh9OHcyaDF",
        "outputId": "eb656189-f882-4ef9-c3ea-25178e4b9602"
      },
      "source": [
        "size_train = len(mensajes_A_train)\n",
        "size_val = len(mensajes_A_val)\n",
        "size_test = len(mensajes_A_test)\n",
        "\n",
        "print(\"Tamaño train: \", size_train)\n",
        "print(\"Tamaño val: \", size_val)\n",
        "print(\"Tamaño test: \", size_test)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tamaño train:  4439\n",
            "Tamaño val:  495\n",
            "Tamaño test:  4906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhjdHKwwz4fd",
        "outputId": "9a76ec6c-2853-487c-c93d-0518005d2908"
      },
      "source": [
        "proporcion_train = (size_train/(size_train + size_val + size_test))*100\n",
        "proporcion_val = (size_val/(size_train + size_val + size_test))*100\n",
        "proporcion_test = (size_test/(size_train + size_val + size_test))*100\n",
        "\n",
        "print(\"Proporcion train: \", round(proporcion_train, 2))\n",
        "print(\"Proporcion val: \", round(proporcion_val, 2))\n",
        "print(\"Proporcion test: \", round(proporcion_test, 2))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Proporcion train:  45.11\n",
            "Proporcion val:  5.03\n",
            "Proporcion test:  49.86\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRdHRCcjyaIx"
      },
      "source": [
        "# Ahora debemos usar la codificacion Word2Vec\n",
        "# Pero primero que todo debemos realizar padding\n",
        "\n",
        "#mensajes_A_train\n",
        "#mensajes_B_train\n",
        "\n",
        "#mensajes_A_val\n",
        "#mensajes_B_val\n",
        "\n",
        "#mensajes_A_test\n",
        "#mensajes_B_test"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHQd2Pv70WD0"
      },
      "source": [
        "for i in range(len(mensajes_A_train)):\n",
        "  mensajes_A_train[i] = mensajes_A_train[i].split(' ')\n",
        "\n",
        "for i in range(len(mensajes_B_train)):\n",
        "  mensajes_B_train[i] = mensajes_B_train[i].split(' ')\n",
        "\n",
        "#----------------------------------------------------------\n",
        "\n",
        "for i in range(len(mensajes_A_val)):\n",
        "  mensajes_A_val[i] = mensajes_A_val[i].split(' ')\n",
        "\n",
        "for i in range(len(mensajes_B_val)):\n",
        "  mensajes_B_val[i] = mensajes_B_val[i].split(' ')\n",
        "\n",
        "#----------------------------------------------------------\n",
        "\n",
        "for i in range(len(mensajes_A_test)):\n",
        "  mensajes_A_test[i] = mensajes_A_test[i].split(' ')\n",
        "\n",
        "for i in range(len(mensajes_B_test)):\n",
        "  mensajes_B_test[i] = mensajes_B_test[i].split(' ')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3SBNnlV2ugG"
      },
      "source": [
        "largos = []\n",
        "\n",
        "#----------------------------------------------------------\n",
        "\n",
        "for i in range(len(mensajes_A_train)):\n",
        "  largos.append(len(mensajes_A_train[i]))\n",
        "\n",
        "for i in range(len(mensajes_B_train)):\n",
        "  largos.append(len(mensajes_B_train[i]))\n",
        "\n",
        "#----------------------------------------------------------\n",
        "\n",
        "for i in range(len(mensajes_A_val)):\n",
        "  largos.append(len(mensajes_A_val[i]))\n",
        "\n",
        "for i in range(len(mensajes_B_val)):\n",
        "  largos.append(len(mensajes_B_val[i]))\n",
        "\n",
        "#----------------------------------------------------------\n",
        "\n",
        "for i in range(len(mensajes_A_test)):\n",
        "  largos.append(len(mensajes_A_test[i]))\n",
        "\n",
        "for i in range(len(mensajes_B_test)):\n",
        "  largos.append(len(mensajes_B_test[i]))\n",
        "\n",
        "#----------------------------------------------------------"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjJUzKok3fT4"
      },
      "source": [
        "maxim_largo = max(largos)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9F8R8cHp3UfA"
      },
      "source": [
        "# Realizamos el PADDING\n",
        "\n",
        "for i in range(len(mensajes_A_train)):\n",
        "  while len(mensajes_A_train[i]) < maxim_largo:\n",
        "    mensajes_A_train[i].append('')\n",
        "\n",
        "for i in range(len(mensajes_B_train)):\n",
        "  while len(mensajes_B_train[i]) < maxim_largo:\n",
        "    mensajes_B_train[i].append('')\n",
        "\n",
        "#----------------------------------------------------------\n",
        "\n",
        "for i in range(len(mensajes_A_val)):\n",
        "  while len(mensajes_A_val[i]) < maxim_largo:\n",
        "    mensajes_A_val[i].append('')\n",
        "\n",
        "for i in range(len(mensajes_B_val)):\n",
        "  while len(mensajes_B_val[i]) < maxim_largo:\n",
        "    mensajes_B_val[i].append('')\n",
        "\n",
        "#----------------------------------------------------------\n",
        "\n",
        "for i in range(len(mensajes_A_test)):\n",
        "  while len(mensajes_A_test[i]) < maxim_largo:\n",
        "    mensajes_A_test[i].append('')\n",
        "\n",
        "for i in range(len(mensajes_B_test)):\n",
        "  while len(mensajes_B_test[i]) < maxim_largo:\n",
        "    mensajes_B_test[i].append('')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WtZ5RhR4Cqw"
      },
      "source": [
        "# Extraemos todas las oraciones para usarlas en word2vec\n",
        "\n",
        "all_sentences = []\n",
        "\n",
        "#mensajes_A_train\n",
        "#mensajes_B_train\n",
        "\n",
        "#mensajes_A_val\n",
        "#mensajes_B_val\n",
        "\n",
        "#mensajes_A_test\n",
        "#mensajes_B_test\n",
        "\n",
        "for i in mensajes_A_train:\n",
        "  all_sentences.append(i)\n",
        "\n",
        "for i in mensajes_B_train:\n",
        "  all_sentences.append(i)\n",
        "\n",
        "#---------------------------\n",
        "\n",
        "for i in mensajes_A_val:\n",
        "  all_sentences.append(i)\n",
        "\n",
        "for i in mensajes_B_val:\n",
        "  all_sentences.append(i)\n",
        "\n",
        "#---------------------------\n",
        "\n",
        "for i in mensajes_A_test:\n",
        "  all_sentences.append(i)\n",
        "\n",
        "for i in mensajes_B_test:\n",
        "  all_sentences.append(i)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyxwJmEP8POR"
      },
      "source": [
        "# Word2Vec\n",
        "\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufVty-2b-HgP"
      },
      "source": [
        "model = Word2Vec(sentences=all_sentences, size = 300, window=5, min_count=1, workers=4)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyZf9kPl-q-R"
      },
      "source": [
        "a = model.wv['boy']\n",
        "b = model.wv['girl']\n",
        "c = model.wv['ball']\n",
        "d = model.wv['man']\n",
        "e = model.wv['woman']"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17v0_RDu-rAw"
      },
      "source": [
        "t_1 = np.linalg.norm(a-b) #Boy/Girl\n",
        "t_2 = np.linalg.norm(d-e) #Man/Woman\n",
        "t_3 = np.linalg.norm(d-a) #Man/Boy\n",
        "t_4 = np.linalg.norm(e-b) #Woman/Girl\n",
        "\n",
        "t_5 = np.linalg.norm(a-c) #Boy/Ball\n",
        "t_6 = np.linalg.norm(b-c) #Girl/Ball\n",
        "t_7 = np.linalg.norm(d-c) #Man/Ball\n",
        "t_8 = np.linalg.norm(e-c) #Woman/Ball"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OfP7r36-rDc",
        "outputId": "dbfe0563-b9bf-4b46-92a4-387262c64578"
      },
      "source": [
        "t_1"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.7938747"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uICYHj6-rFZ",
        "outputId": "79472002-98e9-4272-8745-57a04277ac0e"
      },
      "source": [
        "t_2"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.443006"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mCLr1MgATZ6",
        "outputId": "2fcf4cc5-172c-4ffb-e041-9b0c73edef1e"
      },
      "source": [
        "t_3"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.891575"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uInzPjh9Bfpe",
        "outputId": "dd3728d5-901d-46e2-baa5-34e965abd872"
      },
      "source": [
        "t_4"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.313189"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmPCosdeBhw7",
        "outputId": "f32ddd4c-46c9-4e68-88d1-f69013d98c3c"
      },
      "source": [
        "t_5"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.125274"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mP_q6hZoBjQy",
        "outputId": "50fd823c-335e-4d3e-fc94-5fe3ad94f4d4"
      },
      "source": [
        "t_6"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.795775"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGNTjLy2BkZA",
        "outputId": "4fb6e254-209e-4e82-a3c0-580bfdb98678"
      },
      "source": [
        "t_7"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11.414353"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogCH_ot6BmuX",
        "outputId": "b6e03fc6-dd73-4547-a223-3fe7557e05e4"
      },
      "source": [
        "t_8"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13.167866"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpZ_SMDcBuYJ"
      },
      "source": [
        "#mensajes_A_train\n",
        "#mensajes_B_train\n",
        "\n",
        "#mensajes_A_val\n",
        "#mensajes_B_val\n",
        "\n",
        "#mensajes_A_test\n",
        "#mensajes_B_test"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArKJwkd_QK7p"
      },
      "source": [
        "def calcular_promedio(lista_frase):\n",
        "  lista_promedio = []\n",
        "  for i in range(len(lista_frase[0])):\n",
        "    suma = 0\n",
        "    for j in range(len(lista_frase)):\n",
        "      suma = suma + lista_frase[j][i]\n",
        "    suma = suma/len(lista_frase)\n",
        "    lista_promedio.append([suma])\n",
        "  return lista_promedio"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf7draGtBua_"
      },
      "source": [
        "input_seq_A_train = []\n",
        "\n",
        "for i in range(len(mensajes_A_train)):\n",
        "  lista_frase = []\n",
        "  for j in range(len(mensajes_A_train[i])):\n",
        "    word = mensajes_A_train[i][j]\n",
        "    lista_frase.append(model.wv[word])\n",
        "  lista_agregar = lista_frase\n",
        "  input_seq_A_train.append(lista_agregar)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4g8THoiSMk3"
      },
      "source": [
        "input_seq_B_train = []\n",
        "\n",
        "for i in range(len(mensajes_B_train)):\n",
        "  lista_frase = []\n",
        "  for j in range(len(mensajes_B_train[i])):\n",
        "    word = mensajes_B_train[i][j]\n",
        "    lista_frase.append(model.wv[word])\n",
        "  lista_agregar = lista_frase\n",
        "  input_seq_B_train.append(lista_agregar)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDHCdvFHShpW"
      },
      "source": [
        "input_seq_A_val = []\n",
        "\n",
        "for i in range(len(mensajes_A_val)):\n",
        "  lista_frase = []\n",
        "  for j in range(len(mensajes_A_val[i])):\n",
        "    word = mensajes_A_val[i][j]\n",
        "    lista_frase.append(model.wv[word])\n",
        "  lista_agregar = lista_frase\n",
        "  input_seq_A_val.append(lista_agregar)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edwT8rnBSmZ-"
      },
      "source": [
        "input_seq_B_val = []\n",
        "\n",
        "for i in range(len(mensajes_B_val)):\n",
        "  lista_frase = []\n",
        "  for j in range(len(mensajes_B_val[i])):\n",
        "    word = mensajes_B_val[i][j]\n",
        "    lista_frase.append(model.wv[word])\n",
        "  lista_agregar = lista_frase\n",
        "  input_seq_B_val.append(lista_agregar)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4ypHZyWSmdZ"
      },
      "source": [
        "input_seq_A_test = []\n",
        "\n",
        "for i in range(len(mensajes_A_test)):\n",
        "  lista_frase = []\n",
        "  for j in range(len(mensajes_A_test[i])):\n",
        "    word = mensajes_A_test[i][j]\n",
        "    lista_frase.append(model.wv[word])\n",
        "  lista_agregar = lista_frase\n",
        "  input_seq_A_test.append(lista_agregar)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80aQ7SCiS619"
      },
      "source": [
        "input_seq_B_test = []\n",
        "\n",
        "for i in range(len(mensajes_B_test)):\n",
        "  lista_frase = []\n",
        "  for j in range(len(mensajes_B_test[i])):\n",
        "    word = mensajes_B_test[i][j]\n",
        "    lista_frase.append(model.wv[word])\n",
        "  lista_agregar = lista_frase\n",
        "  input_seq_B_test.append(lista_agregar)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT-PIkZfS649"
      },
      "source": [
        "input_seq_A_train = torch.tensor(input_seq_A_train)\n",
        "input_seq_B_train = torch.tensor(input_seq_B_train)\n",
        "\n",
        "input_seq_A_val = torch.tensor(input_seq_A_val)\n",
        "input_seq_B_val = torch.tensor(input_seq_B_val)\n",
        "\n",
        "input_seq_A_test = torch.tensor(input_seq_A_test)\n",
        "input_seq_B_test = torch.tensor(input_seq_B_test)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roC4scFaS67x",
        "outputId": "f09d7dab-23d3-409e-aff6-9c475c07b5b9"
      },
      "source": [
        "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")    \n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_6XSsjbSmhx"
      },
      "source": [
        "input_seq_A_train = input_seq_A_train.to(device)\n",
        "input_seq_B_train = input_seq_B_train.to(device)\n",
        "\n",
        "input_seq_A_val = input_seq_A_val.to(device)\n",
        "input_seq_B_val = input_seq_B_val.to(device)\n",
        "\n",
        "input_seq_A_test = input_seq_A_test.to(device)\n",
        "input_seq_B_test = input_seq_B_test.to(device)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd5JlvUgb6nF"
      },
      "source": [
        "input_seq_train = torch.cat((input_seq_A_train, input_seq_B_train), 0)\n",
        "input_seq_val = torch.cat((input_seq_A_val, input_seq_B_val), 0)\n",
        "input_seq_test = torch.cat((input_seq_A_test, input_seq_B_test), 0)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2pPFZK-or16"
      },
      "source": [
        "corte = 3 # Cut score\n",
        "y_train = []\n",
        "\n",
        "for i in range(len(scores_train)):\n",
        "  if scores_train[i] >= corte:\n",
        "    y_train.append(1)\n",
        "  else:\n",
        "    y_train.append(0)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyYV8HfJoxzp"
      },
      "source": [
        "y_train = torch.tensor(y_train)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl7X0NQco2RU"
      },
      "source": [
        "y_train = y_train.to(device)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUdkmX-Iz_QT"
      },
      "source": [
        "corte = 3 # Cut score\n",
        "y_val = []\n",
        "\n",
        "for i in range(len(scores_val)):\n",
        "  if scores_val[i] >= corte:\n",
        "    y_val.append(1)\n",
        "  else:\n",
        "    y_val.append(0)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYF0cg9Z1V_5"
      },
      "source": [
        "corte = 3 # Cut score\n",
        "y_test = []\n",
        "\n",
        "for i in range(len(scores_test)):\n",
        "  if scores_test[i] >= corte:\n",
        "    y_test.append(1)\n",
        "  else:\n",
        "    y_test.append(0)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQUdfQxEo7ez"
      },
      "source": [
        "def pair_rkg_loss(out_1, out_2, y, m):\n",
        "  total_loss = 0\n",
        "  total_loss = torch.tensor(total_loss)\n",
        "  total_loss.to(device)\n",
        "\n",
        "  for i in range(len(out_1)):\n",
        "    o_1 = out_1[i]\n",
        "    o_2 = out_2[i]\n",
        "\n",
        "    dist = torch.norm(o_1 - o_2)\n",
        "\n",
        "    loss_1 = y[i]*dist\n",
        "    loss_2 = (1-y[i])*max(0, (m-dist))\n",
        "\n",
        "    loss = loss_1 + loss_2\n",
        "\n",
        "    total_loss = total_loss + loss\n",
        "  \n",
        "  total_loss = total_loss/len(out_1)\n",
        "\n",
        "  return total_loss.to(device)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyFla0SabR0O"
      },
      "source": [
        "# Ahora partimos creando la red"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryTiE4TybR3E"
      },
      "source": [
        "class SIAMESE_model(nn.Module):\n",
        "    def __init__(self, input_size, hidden_dim, n_layers, device):\n",
        "        super(SIAMESE_model, self).__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size, hidden_dim, n_layers, batch_first=True)\n",
        "\n",
        "        self.device = device\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        batch_size = int(x.size(0)/2)\n",
        "\n",
        "        h_1 = self.init_hidden(batch_size)\n",
        "        c_1 = self.init_hidden(batch_size)\n",
        "\n",
        "        h_2 = self.init_hidden(batch_size)\n",
        "        c_2 = self.init_hidden(batch_size)\n",
        "\n",
        "        input_A = x[0:int(len(x)/2)]\n",
        "        input_B = x[int(len(x)/2): len(x)]\n",
        "\n",
        "        input_A.to(self.device)\n",
        "        input_B.to(self.device)\n",
        "\n",
        "        out_1, (h_1, c_1) = self.lstm(input_A, (h_1, c_1))\n",
        "\n",
        "        out_2, (h_2, c_2) = self.lstm(input_B, (h_2, c_2))\n",
        "        \n",
        "        return out_1.to(self.device), out_2.to(self.device), (h_1.to(self.device), c_1.to(self.device)), (h_2.to(self.device), c_2.to(self.device))\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
        "        return hidden.to(self.device)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtbAeF5pbR5r"
      },
      "source": [
        "model = SIAMESE_model(300, 10, 1, device)\n",
        "model.to(device)\n",
        "\n",
        "n_epochs = 100\n",
        "lr = 0.01*5\n",
        "m = 10\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UuserBjbR78",
        "outputId": "6f64563b-f17d-4ba0-c58a-e68308906003"
      },
      "source": [
        "# Entrenamiento\n",
        "\n",
        "epocas_totales = []\n",
        "loss_train_totales = []\n",
        "loss_val_totales = []\n",
        "loss_test_totales = []\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "  start = time.time()\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
        "\n",
        "  out_1, out_2, _, _ = model(input_seq_train)\n",
        "\n",
        "  loss_train = pair_rkg_loss(out_1, out_2, y_train, m)\n",
        "\n",
        "  loss_train.backward() # Does backpropagation and calculates gradients\n",
        "  optimizer.step() # Updates the weights accordingly\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  out_1_val, out_2_val, _, _ = model(input_seq_val)\n",
        "  loss_val = pair_rkg_loss(out_1_val, out_2_val, y_val, m)\n",
        "\n",
        "  loss_val_totales.append(loss_val)\n",
        "\n",
        "  out_1_test, out_2_test, _, _ = model(input_seq_test)\n",
        "  loss_test = pair_rkg_loss(out_1_test, out_2_test, y_test, m)\n",
        "\n",
        "  loss_test_totales.append(loss_test)\n",
        "\n",
        "\n",
        "\n",
        "  epocas_totales.append(epoch)\n",
        "\n",
        "  loss_train_totales.append(loss_train.item())\n",
        "\n",
        "  end = time.time()\n",
        "\n",
        "  print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
        "  print(\"Loss Train Epoch: {:.4f}.............\".format(loss_train.item()), end =' ')\n",
        "  print(\"Time Epoch: {}\".format(end-start))  "
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/100............. Loss Train Epoch: 3.3075............. Time Epoch: 2.581993818283081\n",
            "Epoch: 2/100............. Loss Train Epoch: 2.6837............. Time Epoch: 2.5784761905670166\n",
            "Epoch: 3/100............. Loss Train Epoch: 2.5038............. Time Epoch: 2.5633139610290527\n",
            "Epoch: 4/100............. Loss Train Epoch: 2.4523............. Time Epoch: 2.539755344390869\n",
            "Epoch: 5/100............. Loss Train Epoch: 2.4329............. Time Epoch: 2.5786709785461426\n",
            "Epoch: 6/100............. Loss Train Epoch: 2.4238............. Time Epoch: 2.5452911853790283\n",
            "Epoch: 7/100............. Loss Train Epoch: 2.4185............. Time Epoch: 2.5849688053131104\n",
            "Epoch: 8/100............. Loss Train Epoch: 2.4149............. Time Epoch: 2.5437350273132324\n",
            "Epoch: 9/100............. Loss Train Epoch: 2.4124............. Time Epoch: 2.5553956031799316\n",
            "Epoch: 10/100............. Loss Train Epoch: 2.4106............. Time Epoch: 2.588533401489258\n",
            "Epoch: 11/100............. Loss Train Epoch: 2.4093............. Time Epoch: 2.5373306274414062\n",
            "Epoch: 12/100............. Loss Train Epoch: 2.4083............. Time Epoch: 2.5316731929779053\n",
            "Epoch: 13/100............. Loss Train Epoch: 2.4075............. Time Epoch: 2.5446178913116455\n",
            "Epoch: 14/100............. Loss Train Epoch: 2.4069............. Time Epoch: 2.5883824825286865\n",
            "Epoch: 15/100............. Loss Train Epoch: 2.4064............. Time Epoch: 2.577211618423462\n",
            "Epoch: 16/100............. Loss Train Epoch: 2.4060............. Time Epoch: 2.6109628677368164\n",
            "Epoch: 17/100............. Loss Train Epoch: 2.4056............. Time Epoch: 2.5705182552337646\n",
            "Epoch: 18/100............. Loss Train Epoch: 2.4053............. Time Epoch: 2.5988595485687256\n",
            "Epoch: 19/100............. Loss Train Epoch: 2.4050............. Time Epoch: 2.5680418014526367\n",
            "Epoch: 20/100............. Loss Train Epoch: 2.4046............. Time Epoch: 2.609809637069702\n",
            "Epoch: 21/100............. Loss Train Epoch: 2.4044............. Time Epoch: 2.6787095069885254\n",
            "Epoch: 22/100............. Loss Train Epoch: 2.4041............. Time Epoch: 2.61378812789917\n",
            "Epoch: 23/100............. Loss Train Epoch: 2.4038............. Time Epoch: 2.5978641510009766\n",
            "Epoch: 24/100............. Loss Train Epoch: 2.4036............. Time Epoch: 2.578056812286377\n",
            "Epoch: 25/100............. Loss Train Epoch: 2.4034............. Time Epoch: 2.5751123428344727\n",
            "Epoch: 26/100............. Loss Train Epoch: 2.4032............. Time Epoch: 2.558664083480835\n",
            "Epoch: 27/100............. Loss Train Epoch: 2.4031............. Time Epoch: 2.571925401687622\n",
            "Epoch: 28/100............. Loss Train Epoch: 2.4029............. Time Epoch: 2.5932364463806152\n",
            "Epoch: 29/100............. Loss Train Epoch: 2.4028............. Time Epoch: 2.5700876712799072\n",
            "Epoch: 30/100............. Loss Train Epoch: 2.4027............. Time Epoch: 2.5667543411254883\n",
            "Epoch: 31/100............. Loss Train Epoch: 2.4026............. Time Epoch: 2.582502841949463\n",
            "Epoch: 32/100............. Loss Train Epoch: 2.4025............. Time Epoch: 2.58449649810791\n",
            "Epoch: 33/100............. Loss Train Epoch: 2.4024............. Time Epoch: 2.5823473930358887\n",
            "Epoch: 34/100............. Loss Train Epoch: 2.4023............. Time Epoch: 2.588852643966675\n",
            "Epoch: 35/100............. Loss Train Epoch: 2.4022............. Time Epoch: 2.5538179874420166\n",
            "Epoch: 36/100............. Loss Train Epoch: 2.4021............. Time Epoch: 2.564281940460205\n",
            "Epoch: 37/100............. Loss Train Epoch: 2.4020............. Time Epoch: 2.567702531814575\n",
            "Epoch: 38/100............. Loss Train Epoch: 2.4019............. Time Epoch: 2.55706787109375\n",
            "Epoch: 39/100............. Loss Train Epoch: 2.4018............. Time Epoch: 2.5593926906585693\n",
            "Epoch: 40/100............. Loss Train Epoch: 2.4018............. Time Epoch: 2.5698347091674805\n",
            "Epoch: 41/100............. Loss Train Epoch: 2.4017............. Time Epoch: 2.6431679725646973\n",
            "Epoch: 42/100............. Loss Train Epoch: 2.4016............. Time Epoch: 2.5683987140655518\n",
            "Epoch: 43/100............. Loss Train Epoch: 2.4016............. Time Epoch: 2.5377955436706543\n",
            "Epoch: 44/100............. Loss Train Epoch: 2.4015............. Time Epoch: 2.5722639560699463\n",
            "Epoch: 45/100............. Loss Train Epoch: 2.4015............. Time Epoch: 2.592442274093628\n",
            "Epoch: 46/100............. Loss Train Epoch: 2.4014............. Time Epoch: 2.5681867599487305\n",
            "Epoch: 47/100............. Loss Train Epoch: 2.4014............. Time Epoch: 2.581725597381592\n",
            "Epoch: 48/100............. Loss Train Epoch: 2.4013............. Time Epoch: 2.5963995456695557\n",
            "Epoch: 49/100............. Loss Train Epoch: 2.4013............. Time Epoch: 2.5818541049957275\n",
            "Epoch: 50/100............. Loss Train Epoch: 2.4012............. Time Epoch: 2.564176082611084\n",
            "Epoch: 51/100............. Loss Train Epoch: 2.4012............. Time Epoch: 2.566086769104004\n",
            "Epoch: 52/100............. Loss Train Epoch: 2.4012............. Time Epoch: 2.5591671466827393\n",
            "Epoch: 53/100............. Loss Train Epoch: 2.4011............. Time Epoch: 2.5718939304351807\n",
            "Epoch: 54/100............. Loss Train Epoch: 2.4011............. Time Epoch: 2.548250198364258\n",
            "Epoch: 55/100............. Loss Train Epoch: 2.4011............. Time Epoch: 2.558712959289551\n",
            "Epoch: 56/100............. Loss Train Epoch: 2.4010............. Time Epoch: 2.5648810863494873\n",
            "Epoch: 57/100............. Loss Train Epoch: 2.4010............. Time Epoch: 2.584292411804199\n",
            "Epoch: 58/100............. Loss Train Epoch: 2.4010............. Time Epoch: 2.5661141872406006\n",
            "Epoch: 59/100............. Loss Train Epoch: 2.4009............. Time Epoch: 2.5516257286071777\n",
            "Epoch: 60/100............. Loss Train Epoch: 2.4009............. Time Epoch: 2.555438756942749\n",
            "Epoch: 61/100............. Loss Train Epoch: 2.4009............. Time Epoch: 2.5614092350006104\n",
            "Epoch: 62/100............. Loss Train Epoch: 2.4008............. Time Epoch: 2.5657174587249756\n",
            "Epoch: 63/100............. Loss Train Epoch: 2.4008............. Time Epoch: 2.54681658744812\n",
            "Epoch: 64/100............. Loss Train Epoch: 2.4008............. Time Epoch: 2.5672812461853027\n",
            "Epoch: 65/100............. Loss Train Epoch: 2.4007............. Time Epoch: 2.5400195121765137\n",
            "Epoch: 66/100............. Loss Train Epoch: 2.4007............. Time Epoch: 2.601855754852295\n",
            "Epoch: 67/100............. Loss Train Epoch: 2.4007............. Time Epoch: 2.576915979385376\n",
            "Epoch: 68/100............. Loss Train Epoch: 2.4006............. Time Epoch: 2.5772321224212646\n",
            "Epoch: 69/100............. Loss Train Epoch: 2.4006............. Time Epoch: 2.5812413692474365\n",
            "Epoch: 70/100............. Loss Train Epoch: 2.4006............. Time Epoch: 2.5876951217651367\n",
            "Epoch: 71/100............. Loss Train Epoch: 2.4006............. Time Epoch: 2.551590919494629\n",
            "Epoch: 72/100............. Loss Train Epoch: 2.4006............. Time Epoch: 2.535430431365967\n",
            "Epoch: 73/100............. Loss Train Epoch: 2.4005............. Time Epoch: 2.5628535747528076\n",
            "Epoch: 74/100............. Loss Train Epoch: 2.4005............. Time Epoch: 2.573549509048462\n",
            "Epoch: 75/100............. Loss Train Epoch: 2.4005............. Time Epoch: 2.5999104976654053\n",
            "Epoch: 76/100............. Loss Train Epoch: 2.4005............. Time Epoch: 2.5816986560821533\n",
            "Epoch: 77/100............. Loss Train Epoch: 2.4005............. Time Epoch: 2.5872979164123535\n",
            "Epoch: 78/100............. Loss Train Epoch: 2.4004............. Time Epoch: 2.5811007022857666\n",
            "Epoch: 79/100............. Loss Train Epoch: 2.4004............. Time Epoch: 2.5869874954223633\n",
            "Epoch: 80/100............. Loss Train Epoch: 2.4004............. Time Epoch: 2.584322452545166\n",
            "Epoch: 81/100............. Loss Train Epoch: 2.4004............. Time Epoch: 2.548034906387329\n",
            "Epoch: 82/100............. Loss Train Epoch: 2.4004............. Time Epoch: 2.5753471851348877\n",
            "Epoch: 83/100............. Loss Train Epoch: 2.4003............. Time Epoch: 2.5949714183807373\n",
            "Epoch: 84/100............. Loss Train Epoch: 2.4003............. Time Epoch: 2.7395291328430176\n",
            "Epoch: 85/100............. Loss Train Epoch: 2.4003............. Time Epoch: 2.5687129497528076\n",
            "Epoch: 86/100............. Loss Train Epoch: 2.4003............. Time Epoch: 2.562394142150879\n",
            "Epoch: 87/100............. Loss Train Epoch: 2.4003............. Time Epoch: 2.5618629455566406\n",
            "Epoch: 88/100............. Loss Train Epoch: 2.4003............. Time Epoch: 2.562828302383423\n",
            "Epoch: 89/100............. Loss Train Epoch: 2.4003............. Time Epoch: 2.5709969997406006\n",
            "Epoch: 90/100............. Loss Train Epoch: 2.4002............. Time Epoch: 2.5702126026153564\n",
            "Epoch: 91/100............. Loss Train Epoch: 2.4002............. Time Epoch: 2.564877510070801\n",
            "Epoch: 92/100............. Loss Train Epoch: 2.4002............. Time Epoch: 2.5681731700897217\n",
            "Epoch: 93/100............. Loss Train Epoch: 2.4002............. Time Epoch: 2.554030179977417\n",
            "Epoch: 94/100............. Loss Train Epoch: 2.4002............. Time Epoch: 2.5764997005462646\n",
            "Epoch: 95/100............. Loss Train Epoch: 2.4002............. Time Epoch: 2.590319871902466\n",
            "Epoch: 96/100............. Loss Train Epoch: 2.4002............. Time Epoch: 2.6043927669525146\n",
            "Epoch: 97/100............. Loss Train Epoch: 2.4002............. Time Epoch: 2.558795928955078\n",
            "Epoch: 98/100............. Loss Train Epoch: 2.4001............. Time Epoch: 2.583618402481079\n",
            "Epoch: 99/100............. Loss Train Epoch: 2.4001............. Time Epoch: 2.562333822250366\n",
            "Epoch: 100/100............. Loss Train Epoch: 2.4001............. Time Epoch: 2.5730369091033936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhrFhDUzQjCj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "c264f548-2716-4631-d453-84ef90b0fbd6"
      },
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "\n",
        "plt.plot(epocas_totales, loss_train_totales, color = \"red\")\n",
        "plt.plot(epocas_totales, loss_val_totales, color = \"blue\")\n",
        "plt.plot(epocas_totales, loss_test_totales, color = \"green\")\n",
        "plt.legend(['Perdida de Entrenamiento', 'Perdida de Validación', 'Perdida de Test'], loc='upper left')\n",
        "\n",
        "#plt.yscale('log')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# loss_final = 2.4 if lr_optimo = 0.01*5 "
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BUedNWeu9Qi"
      },
      "source": [
        ""
      ],
      "execution_count": 50,
      "outputs": []
    }
  ]
}